{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture --no-stderr\n",
    "# %pip install -U langchain_community tiktoken langchainhub chromadb langchain langgraph nlangchain_ollama langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = \"mistral\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content: \"content\": \"You will get instructions for code to write.\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\n\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\n\\nThen you will output the content of each file including ALL code.\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\nFILENAME is the lowercase file name including the file extension,\\nLANG is the markup code block language for the code's language, and CODE is the code:\\n\\nFILENAME\\n```LANG\\nCODE\\n```\\n\\nYou will start with the \\\"entrypoint\\\" file, then go to the ones that are imported by that file, and so on.\\nPlease note that the code should be fully functional. No placeholders.\\n\\nFollow a language and framework appropriate best practice file naming convention.\\nMake sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\\nEnsure to implement all code, if you are unsure, write a plausible implementation.\\nInclude module dependency or package manager dependency definition file.\\nBefore you finish, double check that all parts of the architecture is present in the files.\\n\\nUseful to know:\\nYou almost always put different classes in different files.\\nFor Python, you always create an appropriate requirements.txt file.\\nFor NodeJS, you always create an appropriate package.json file.\\nYou always add a comment briefly describing the purpose of the function definition.\\nYou try to add comments explaining very complex bits of logic.\\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\\npackage/project.\\n\\n\\nPython toolbelt preferences:\\n- pytest\\n- dataclasses\\n\"\n",
      "  },, Metadata: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}\n",
      "Content: Commands:\n",
      "1. Google Search: \"google\", args: \"input\": \"<search>\"\n",
      "2. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\n",
      "3. Start GPT Agent: \"start_agent\", args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\n",
      "4. Message GPT Agent: \"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\n",
      "5. List GPT Agents: \"list_agents\", args:\n",
      "6. Delete GPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\n",
      "7. Clone Repository: \"clone_repository\", args: \"repository_url\": \"<url>\", \"clone_path\": \"<directory>\"\n",
      "8. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\n",
      "9. Read file: \"read_file\", args: \"file\": \"<file>\"\n",
      "10. Append to file: \"append_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\n",
      "11. Delete file: \"delete_file\", args: \"file\": \"<file>\"\n",
      "12. Search Files: \"search_files\", args: \"directory\": \"<directory>\"\n",
      "13. Analyze Code: \"analyze_code\", args: \"code\": \"<full_code_string>\"\n",
      "14. Get Improved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\n",
      "15. Write Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\n",
      "16. Execute Python File: \"execute_python_file\", args: \"file\": \"<file>\"\n",
      "17. Generate Image: \"generate_image\", args: \"prompt\": \"<prompt>\"\n",
      "18. Send Tweet: \"send_tweet\", args: \"text\": \"<text>\"\n",
      "19. Do Nothing: \"do_nothing\", args:, Metadata: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}\n",
      "Content: You will get instructions for code to write.\n",
      "You will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\n",
      "Make sure that every detail of the architecture is, in the end, implemented as code.\n",
      "Think step by step and reason yourself to the right decisions to make sure we get it right.\n",
      "You will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\n",
      "Then you will output the content of each file including ALL code.\n",
      "Each file must strictly follow a markdown code block format, where the following tokens must be replaced such that\n",
      "FILENAME is the lowercase file name including the file extension,\n",
      "LANG is the markup code block language for the code’s language, and CODE is the code:\n",
      "FILENAME\n",
      "CODE\n",
      "You will start with the “entrypoint” file, then go to the ones that are imported by that file, and so on.\n",
      "Please note that the code should be fully functional. No placeholders.\n",
      "Follow a language and framework appropriate best practice file naming convention.\n",
      "Make sure that files contain all imports, types etc. Make sure that code in different files are compatible with each other.\n",
      "Ensure to implement all code, if you are unsure, write a plausible implementation.\n",
      "Include module dependency or package manager dependency definition file.\n",
      "Before you finish, double check that all parts of the architecture is present in the files.\n",
      "Useful to know:\n",
      "You almost always put different classes in different files.\n",
      "For Python, you always create an appropriate requirements.txt file.\n",
      "For NodeJS, you always create an appropriate package.json file.\n",
      "You always add a comment briefly describing the purpose of the function definition.\n",
      "You try to add comments explaining very complex bits of logic.\n",
      "You always follow the best practices for the requested languages in terms of describing the code written as a defined\n",
      "package/project.\n",
      "Python toolbelt preferences:\n",
      "\n",
      "pytest\n",
      "dataclasses, Metadata: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}\n",
      "Content: [19] Xie et al. “Defending ChatGPT against Jailbreak Attack via Self-Reminder.” Research Square (2023)\n",
      "[20] Jones et al. “Automatically Auditing Large Language Models via Discrete Optimization.” arXiv preprint arXiv:2303.04381 (2023)\n",
      "[21] Greshake et al. “Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection.” arXiv preprint arXiv:2302.12173(2023)\n",
      "[22] Jain et al. “Baseline Defenses for Adversarial Attacks Against Aligned Language Models.” arXiv preprint arXiv:2309.00614 (2023)\n",
      "[23] Wei et al. “Jailbroken: How Does LLM Safety Training Fail?” arXiv preprint arXiv:2307.02483 (2023)\n",
      "[24] Wei & Zou. “EDA: Easy data augmentation techniques for boosting performance on text classification tasks.”  EMNLP-IJCNLP 2019.\n",
      "[25] www.jailbreakchat.com\n",
      "[26] WitchBOT. “You can use GPT-4 to create prompt injections against GPT-4” Apr 2023., Metadata: {'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/', 'title': \"Adversarial Attacks on LLMs | Lil'Log\", 'description': 'The use of large language models in the real world has strongly accelerated by the launch of ChatGPT. We (including my team at OpenAI, shoutout to them) have invested a lot of effort to build default safe behavior into the model during the alignment process (e.g. via RLHF). However, adversarial attacks or jailbreak prompts could potentially trigger the model to output something undesired.\\nA large body of ground work on adversarial attacks is on images, and differently it operates in the continuous, high-dimensional space. Attacks for discrete data like text have been considered to be a lot more challenging, due to lack of direct gradient signals. My past post on Controllable Text Generation is quite relevant to this topic, as attacking LLMs is essentially to control the model to output a certain type of (unsafe) content.', 'language': 'en'}\n",
      "Content: Nlp\n",
      "Language-Model\n",
      "Safety\n",
      "Adversarial Attacks\n",
      "Robustness\n",
      "Redteam\n",
      "\n",
      "\n",
      "\n",
      "« \n",
      "\n",
      "Thinking about High-Quality Human Data\n",
      "\n",
      "\n",
      " »\n",
      "\n",
      "LLM Powered Autonomous Agents\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "© 2024 Lil'Log\n",
      "\n",
      "        Powered by\n",
      "        Hugo &\n",
      "        PaperMod, Metadata: {'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/', 'title': \"Adversarial Attacks on LLMs | Lil'Log\", 'description': 'The use of large language models in the real world has strongly accelerated by the launch of ChatGPT. We (including my team at OpenAI, shoutout to them) have invested a lot of effort to build default safe behavior into the model during the alignment process (e.g. via RLHF). However, adversarial attacks or jailbreak prompts could potentially trigger the model to output something undesired.\\nA large body of ground work on adversarial attacks is on images, and differently it operates in the continuous, high-dimensional space. Attacks for discrete data like text have been considered to be a lot more challenging, due to lack of direct gradient signals. My past post on Controllable Text Generation is quite relevant to this topic, as attacking LLMs is essentially to control the model to output a certain type of (unsafe) content.', 'language': 'en'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hasans\\AppData\\Local\\Temp\\ipykernel_15628\\4280462970.py:45: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retrieved_docs = retriever.get_relevant_documents(query)\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.docstore.in_memory import InMemoryDocstore\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"multi-qa-mpnet-base-dot-v1\")\n",
    "\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_spliter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=500, chunk_overlap=100\n",
    ")\n",
    "\n",
    "doc_splits = text_spliter.split_documents(docs_list)\n",
    "doc_embedding = [embedding_model.embed_query(doc.page_content) for doc in doc_splits]\n",
    "\n",
    "dimension = len(doc_embedding[0])\n",
    "faiss_index = faiss.IndexFlatL2(dimension)\n",
    "faiss_index.add(np.array(doc_embedding))\n",
    "\n",
    "docstore = InMemoryDocstore({str(i): doc for i, doc in enumerate(doc_splits)})\n",
    "index_to_docstore_id = {i: str(i) for i in range(len(doc_splits))}\n",
    "\n",
    "\n",
    "vectorstore = FAISS(\n",
    "    embedding_function=embedding_model,\n",
    "    docstore=docstore,\n",
    "    index_to_docstore_id=index_to_docstore_id,\n",
    "    index=faiss_index\n",
    ")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type='similarity', search_kwargs={'k': 5})\n",
    "\n",
    "query = \"Tell me about LangChain\"\n",
    "retrieved_docs = retriever.get_relevant_documents(query)\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    print(f\"Content: {doc.page_content}, Metadata: {doc.metadata}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content=\"LLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\nemojisearch.app\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences\\n\\n\\n\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\"),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content=\"Memory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions\\n\\nPlanning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X's plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\"),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='Memory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\nFig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='Fig. 7. Comparison of AD, ED, source policy and RL^2 on environments that require memory and exploration. Only binary reward is assigned. The source policies are trained with A3C for \"dark\" environments and DQN for watermaze.(Image source: Laskin et al. 2023)\\nComponent Two: Memory#\\n(Big thank you to ChatGPT for helping me draft this section. I’ve learned a lot about the human brain and data structure for fast MIPS in my conversations with ChatGPT.)\\nTypes of Memory#\\nMemory can be defined as the processes used to acquire, store, retain, and later retrieve information. There are several types of memory in human brains.\\n\\n\\nSensory Memory: This is the earliest stage of memory, providing the ability to retain impressions of sensory information (visual, auditory, etc) after the original stimuli have ended. Sensory memory typically only lasts for up to a few seconds. Subcategories include iconic memory (visual), echoic memory (auditory), and haptic memory (touch).\\n\\n\\nShort-Term Memory (STM) or Working Memory: It stores information that we are currently aware of and needed to carry out complex cognitive tasks such as learning and reasoning. Short-term memory is believed to have the capacity of about 7 items (Miller 1956) and lasts for 20-30 seconds.\\n\\n\\nLong-Term Memory (LTM): Long-term memory can store information for a remarkably long time, ranging from a few days to decades, with an essentially unlimited storage capacity. There are two subtypes of LTM:\\n\\nExplicit / declarative memory: This is memory of facts and events, and refers to those memories that can be consciously recalled, including episodic memory (events and experiences) and semantic memory (facts and concepts).\\nImplicit / procedural memory: This type of memory is unconscious and involves skills and routines that are performed automatically, like riding a bike or typing on a keyboard.\\n\\n\\n\\n\\nFig. 8. Categorization of human memory.\\nWe can roughly consider the following mappings:')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"agent memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retriever Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "    Here is the user question: {question} \\n\n",
    "    If the document contains keywords related to the user question, grade it as relevant. \\n\n",
    "    It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no premable or explanation.\"\"\",\n",
    "    input_variables=[\"question\", \"document\"]\n",
    ")\n",
    "\n",
    "retriever_grader = prompt | llm | JsonOutputParser()\n",
    "question = \"agent memory\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_text = docs[1].page_content\n",
    "print(retriever_grader.invoke(\n",
    "    {\n",
    "        \"question\" : question,\n",
    "        \"document\" : doc_text\n",
    "    }\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question = \"huggingface\"\n",
    "# docs = retriever.invoke(question)\n",
    "# doc_text = docs[1].page_content\n",
    "# print(retriever_grader.invoke(\n",
    "#     {\n",
    "#         \"question\" : question,\n",
    "#         \"document\" : doc_text\n",
    "#     }\n",
    "# ))\n",
    "# print(docs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The post discusses the concept of an autonomous agent system powered by a large language model (LLM). This system is designed to perform complex tasks efficiently and adaptively, using planning, memory, and tool use.\n",
      "\n",
      "1. Planning: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks. It also reflects on past actions, learns from mistakes, and refines its strategies for future steps to improve the quality of results.\n",
      "\n",
      "2. Memory: The system has two types of memory: short-term (STM) and long-term (LTM). STM stores information that is currently needed for complex cognitive tasks like learning and reasoning, while LTM can store information for a remarkably long time, ranging from a few days to decades. LTM has two subtypes: explicit/declarative memory (memory of facts and events) and implicit/procedural memory (skills and routines performed automatically).\n",
      "\n",
      "3. Tool use: The agent learns to call external APIs for extra information that is missing from the model weights, including current information, code execution capability, access to proprietary information sources, etc. This helps the agent adapt to new situations and environments more effectively.\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "generate_prompt = PromptTemplate(\n",
    "   template= \"\"\"\n",
    "You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "\"\"\",\n",
    "input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "generate_llm = ChatOllama(model=local_llm, temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = generate_prompt | generate_llm | StrOutputParser()\n",
    "\n",
    "generation = rag_chain.invoke(\n",
    "    {\n",
    "        \"context\": docs,\n",
    "        \"question\" : question\n",
    "    }\n",
    ")\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hallucination Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hallucination_model = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "hallucination_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing whether an answer is grounded in / supported by a set of facts. \\n \n",
    "    Here are the facts:\n",
    "    \\n ------- \\n\n",
    "    {documents} \n",
    "    \\n ------- \\n\n",
    "    Here is the answer: {generation}\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the answer is grounded in / supported by a set of facts. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\"\"\",\n",
    "    input_variables=[\"generation\", \"documents\"]\n",
    ")\n",
    "\n",
    "hallucination_grader = hallucination_prompt | hallucination_model | JsonOutputParser()\n",
    "hallucination_grader.invoke(\n",
    "    {\n",
    "        \"documents\" : docs,\n",
    "        \"generation\" : generation\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "grader_model = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "grader_prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a grader assessing whether an answer is useful to resolve a question. \\n \n",
    "    Here is the answer:\n",
    "    \\n ------- \\n\n",
    "    {generation} \n",
    "    \\n ------- \\n\n",
    "    Here is the question: {question}\n",
    "    Give a binary score 'yes' or 'no' to indicate whether the answer is useful to resolve a question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    "    )\n",
    "\n",
    "answer_grader = grader_prompt | grader_model | JsonOutputParser()\n",
    "answer_grader.invoke(\n",
    "    {\n",
    "        \"question\" : question,\n",
    "        \"generation\" : generation\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question Re-Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" What is the function of an agent's memory in a given context?\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_writer_model = ChatOllama(model = local_llm, temperature=0)\n",
    "\n",
    "re_write_prompt = PromptTemplate(\n",
    "        template=\"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "     for vectorstore retrieval. Look at the initial and formulate an improved question. \\n\n",
    "     Here is the initial question: \\n\\n {question}. Improved question with no preamble: \\n \"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    ")\n",
    "\n",
    "question_re_writer = re_write_prompt | re_writer_model | StrOutputParser()\n",
    "question_re_writer.invoke(\n",
    "    {\n",
    "        \"question\" : question\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation:str\n",
    "    documents:List[str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Retrieve\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    print(\"---RETRIEVE---\")\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    documents = retriever.invoke(question)\n",
    "    return{\"documents\":documents, \"question\":question}\n",
    "\n",
    "##Generate\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    generation = rag_chain.invoke({\n",
    "        \"context\" : documents,\n",
    "        \"question\" : question\n",
    "    })\n",
    "    return {\"documents\" : documents,\"question\" : question,\"generation\" : generation}\n",
    "\n",
    "def grade_doduments(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "\n",
    "    filtered_docs = []\n",
    "    for d in documents:\n",
    "        score = retriever_grader.invoke(\n",
    "            {\n",
    "                \"question\" : question,\n",
    "                \"document\" : documents\n",
    "            }\n",
    "        )\n",
    "        grade = score[\"score\"]\n",
    "        if grade == 'yes':\n",
    "            print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "            continue\n",
    "    return {\"documents\" : filtered_docs, \"question\" : question}\n",
    "\n",
    "def transform_query(state):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates question key with a re-phrased question\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "\n",
    "    #re-write question\n",
    "    better_question = question_re_writer.invoke({\"question\":question})\n",
    "    return {\"documents\":documents, \"question\":better_question}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or re-generate a question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    state[\"question\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if not filtered_documents:\n",
    "        print(\n",
    "            \"---DECISION: ALL DOCUMENTS ARE NOT RELEVANT TO QUESTION, TRANSFORM QUERY---\"\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        print(\"---DECISION: GENERATE---\")\n",
    "        return \"generate\"\n",
    "    \n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK HALLICINATION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    score = hallucination_grader.invoke(\n",
    "        {\n",
    "            \"documents\" : documents,\n",
    "            \"generation\" : generation\n",
    "        }\n",
    "    )\n",
    "    grade = score['score']\n",
    "\n",
    "    if grade == \"yes\":\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        print(\"---GRADE GENERATION VS QUESTION---\")\n",
    "        score = answer_grader.invoke({\n",
    "            \"question\":question,\n",
    "            \"generation\":generation\n",
    "        })\n",
    "        grade = score[\"score\"]\n",
    "\n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            print(\"___DECISION: GENERATION DOEST NOT ADDRESS QUESTION---\")\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        print(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"not supported\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "#nodes\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"grade_documents\", grade_doduments)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"transform_query\", transform_query)\n",
    "\n",
    "#edges\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\":\"transform_query\",\n",
    "        \"generate\": \"generate\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": END,\n",
    "        \"useful\":END,\n",
    "        \"not useful\": \"transform_query\"\n",
    "    }\n",
    ")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVE---\n",
      "\"Node 'retrieve:\"\n",
      "'\\n---\\n'\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: GENERATE---\n",
      "\"Node 'grade_documents:\"\n",
      "'\\n---\\n'\n",
      "---GENERATE---\n",
      "---CHECK HALLICINATION---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION VS QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "\"Node 'generate:\"\n",
      "'\\n---\\n'\n",
      "(' In a Large Language Model (LLM) powered autonomous agent system, planning '\n",
      " 'is one of the key components. The agent breaks down complex tasks into '\n",
      " 'smaller, manageable subgoals, enabling efficient handling. This process is '\n",
      " 'often achieved using techniques like Chain of Thought (CoT) or Tree of '\n",
      " 'Thoughts (ToT).\\n'\n",
      " '\\n'\n",
      " '   CoT instructs the model to \"think step by step\" to utilize more test-time '\n",
      " 'computation and decompose hard tasks into smaller and simpler steps. ToT '\n",
      " 'extends CoT by exploring multiple reasoning possibilities at each step, '\n",
      " 'creating a tree structure. The search process can be BFS (breadth-first '\n",
      " 'search) or DFS (depth-first search) with each state evaluated by a '\n",
      " 'classifier or majority vote.\\n'\n",
      " '\\n'\n",
      " '   Task decomposition can also be done using simple prompts like \"Steps for '\n",
      " 'XYZ.\\\\\\\\n1\", \"What are the subgoals for achieving XYZ?\", task-specific '\n",
      " 'instructions, or human inputs. Another approach is LLM+P, which relies on an '\n",
      " 'external classical planner to do long-horizon planning. This approach uses '\n",
      " 'the Planning Domain Definition Language (PDDL) as an intermediate interface '\n",
      " 'to describe the planning problem.\\n'\n",
      " '\\n'\n",
      " '   Self-reflection is another important aspect of planning in these agents. '\n",
      " 'They can critique their own actions, learn from mistakes, and refine their '\n",
      " 'strategies for future steps, thereby improving the quality of their final '\n",
      " 'results. This process helps them adapt and improve over time.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "inputs = {\n",
    "    \"question\" : \"agentic ai and memory usage\"\n",
    "}\n",
    "\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Node '{key}:\")\n",
    "    pprint(\"\\n---\\n\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---RETRIEVE---\n",
      "\"Node 'retrieve:\"\n",
      "'\\n---\\n'\n",
      "---CHECK DOCUMENT RELEVANCE TO QUESTION---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---GRADE: DOCUMENT RELEVANT---\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "---DECISION: GENERATE---\n",
      "\"Node 'grade_documents:\"\n",
      "'\\n---\\n'\n",
      "---GENERATE---\n",
      "---CHECK HALLICINATION---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION VS QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "\"Node 'generate:\"\n",
      "'\\n---\\n'\n",
      "(' The document discusses the concept of building autonomous agents using '\n",
      " 'large language models (LLMs) as their core controllers, with examples such '\n",
      " 'as AutoGPT, GPT-Engineer, and BabyAGI. The agent system consists of several '\n",
      " 'key components, including planning, memory, and tool use.\\n'\n",
      " '\\n'\n",
      " '   In the planning component, the agent breaks down complex tasks into '\n",
      " 'smaller, manageable subgoals to handle them efficiently. This involves '\n",
      " 'self-reflection, where the agent learns from past mistakes and refines its '\n",
      " 'approach for future steps, improving the quality of final results. However, '\n",
      " 'challenges arise due to finite context length, reliability issues with '\n",
      " 'natural language interfaces, and difficulties in long-term planning and task '\n",
      " 'decomposition.\\n'\n",
      " '\\n'\n",
      " '   The memory component includes short-term memory (in-context learning) and '\n",
      " 'long-term memory (capable of retaining and recalling information over '\n",
      " 'extended periods). This is often achieved through the use of external vector '\n",
      " 'stores and fast retrieval systems.\\n'\n",
      " '\\n'\n",
      " '   The tool use component allows the agent to call external APIs for '\n",
      " 'additional information, such as current information, code execution '\n",
      " 'capability, and access to proprietary information sources.\\n'\n",
      " '\\n'\n",
      " '   The document also highlights some challenges faced by these autonomous '\n",
      " 'agents, including their struggle to adjust plans when faced with unexpected '\n",
      " 'errors, making them less robust compared to humans who learn from trial and '\n",
      " 'error. Additionally, the reliability of model outputs is questionable due to '\n",
      " 'formatting errors and occasional rebellious behavior.\\n'\n",
      " '\\n'\n",
      " '   The document was cited as: Weng, Lilian. (Jun 2023). “LLM-powered '\n",
      " 'Autonomous Agents”. Lil’Log. '\n",
      " 'https://lilianweng.github.io/posts/2023-06-23-agent/.')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "inputs = {\n",
    "    \"question\" : \"summarize the indormation you have about agentic ai\"\n",
    "}\n",
    "\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Node '{key}:\")\n",
    "    pprint(\"\\n---\\n\")\n",
    "pprint(value[\"generation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
